### 为什么要使用Redis

1. 高性能
2. 高并发



### Redis除了能做缓存，还能做什么

- 分布式锁
- 限流：一般是通过 Redis + Lua 脚本的方式来实现限流。
- 消息队列：缺点：消息丢失（客户端断开连接或者 Redis 宕机都会导致消息丢失）、消息堆积（发布者发布消息的时候不会管消费者的具体消费能力如何）等问题依然没有一个比较好的解决办法。
- 复杂业务场景



### String 还是 Hash 存储对象数据更好呢？

1. String类型存储的是序列化后的数据，存放的是整个对象。Hash是对对象的每个字段单纯存储，可以获取部分字段的信息，也可以修改或者添加部分字段，节省网络流量。如果对象中某些字段需要经常变动或者经常需要单独查询对象中的个别字段信息，Hash 就非常适合。
2. String 存储相对来说更加节省内存，缓存相同数量的对象数据，String 消耗的内存约是 Hash 的一半。如果系统对性能和资源消耗非常敏感的话，String 就非常适合。





### 如何基于Redis实现分布式锁

Redis滑块锁（Slide Lock）是一种基于Redis的分布式锁实现方式。它利用Redis的特性和命令来实现分布式锁的功能，确保在多个客户端之间对共享资源进行互斥访问。

滑块锁的原理如下：

1. 当一个客户端需要获取锁时，它会向Redis发送一个特定的命令，例如SETNX（SET if Not eXists）。
2. 如果键（Key）不存在，即说明该客户端获取了锁，并设置一个带有过期时间的键值对，表示锁的持有者以及锁的有效期。
3. 如果获取锁失败，客户端会等待一段时间后重试。
4. 如果锁的持有者在锁的有效期内完成了任务，它会释放锁，即删除对应的键。

滑块锁的特点是具有可重入性（Reentrant），即同一个客户端可以多次获取同一个锁，而不会触发死锁。它的实现需要考虑的问题包括获取锁的原子性、锁的超时处理、防止锁续租等，这些问题可以通过使用Redis的事务、Lua脚本和Lua脚本的执行原子性等机制来解决。



## Redis 订阅/发布

有两种模式，基于频道`channel`和基于模式`pattern`两种来发布信息









## 3种常见的缓存读写策略



### Cache Aside Pattern（旁路缓存模式）

实际上是用来维系 db和cache之间的桥梁，结果以db为主

这个模式是最常用的一种模式

写模式是怎样的，读模式是怎样的

缺点：

1. 理论上一样会出现数据不一致的现象
2. 首次请求数据一定不在cache的问题
3. 写操作频繁的话会影响缓存的命中率



### Read/Write Through Pattern （读写穿透）

该服务是把cache作为主要的数据存储。

写模式是什么，读模式是什么



### Write Behind Pattern（异步缓存写入）

由cache 服务来负责 cache 和 db 的读写，和上边一样

但是两个又有很大的不同：

1. **Read/Write Through 是同步更新 cache 和 db**。
2. **而 Write Behind 则是只更新缓存，不直接更新 db，而是改为异步批量的方式来更新 db。注意，是批量**



应用场景很常见：

1. 消息队列中消息的异步写入磁盘
2. MySQL 的 Innodb Buffer Pool 机制都用到了这种策略

Write Behind Pattern 下 db 的写性能非常高，非常适合一些数据经常变化又对数据一致性要求没那么高的场景，比如浏览量、点赞量。



## 5种基本数据结构



### String

String类型可以存储任何类型的数据

应用场景： 

1. 常规数据的存储：session,token,图片地址，序列化后的对象
2. 需要计数的对象：用户单位时间的请求数（简单限流可以用到）、页面单位时间的访问数。
3. 分布式锁： setNx



### List

应用场景

1. 信息流展示：  最新文章，最新动态等等
2. 消息队列



### Hash

是一个 String 类型的 field-value（键值对） 的映射表，特别适合用于存储对象

应用场景：

1. 对象数据存储场景：用户信息，购物车信息，文章信息，商品信息等等。



### Set

Set 类型是一种无序集合，集合中的元素没有先后顺序但都唯一，不想要重复的数据，一般用来求交集



应用场景：

1. 统计文章点赞数量，动态点赞数量等等。
2. 交集，并集，差集的场景。
3. 需要随机获取数据源中的元素的场景：抽奖，随机点名。



### Sorted Set

Set是无序的，而Sorted Set是有序的

1. 根据某些权重进行排序的场景
2. 优先级任务队列



## Redis 线程模型



### Redis单线程模型是什么

**Redis 基于 Reactor 模式设计开发了一套高效的事件处理模型**。 这套事件处理模型是单线程的，所以Redis是单线程模型。虽然文件事件处理器以单线程方式运行，但通过使用 I/O 多路复用程序来监听多个套接字。

因此也就解释了：**既然是单线程，那怎么监听大量的客户端连接呢？**

Redis利用I/O多路复用的方法，降低资源的消耗。



### Redis6.0之前为什么不使用多线程？之后为什么又引入了多线程？

- 单线程编程容易并且更容易维护；
- Redis 的性能瓶颈不在 CPU ，主要在内存和网络；
- 多线程就会存在死锁、线程上下文切换等问题，甚至会影响性能。



**Redis6.0 引入多线程主要是为了提高网络 IO 读写性能**，因为这个算是 Redis 中的一个性能瓶颈（Redis 的瓶颈主要受限于内存和网络）。

虽然，Redis6.0 引入了多线程，但是 Redis 的多线程只是在网络数据的读写这类耗时操作上使用了，执行命令仍然是单线程顺序执行。因此，你也不需要担心线程安全问题。





### Redis后台线程了解吗？

虽然Redis一直是单线程模型。 但是有一些后台线程用于执行一些比较耗时的操作：

1. 通过 `bio_close_file` 后台线程来释放 AOF / RDB 等过程中产生的临时文件资源。
2. 通过 `bio_aof_fsync` 后台线程调用 `fsync` 函数将系统内核缓冲区还未同步到到磁盘的数据强制刷到磁盘。
3. 通过 `bio_lazy_free`后台线程释放大对象（已删除）占用的内存空间.





## Redis 内存管理



### Redis给缓存数据设置过期时间有什么用

**过期时间除了有助于缓解内存的消耗，还有什么其他用么？**



###  Redis 是如何判断数据是否过期的呢？

Redis的过期字典（hash表）来保存数据过期的时间。key指向redis数据库中某个key，值是一个long long 类型的整数。



### 过期的数据删除策略

1. 惰性删除：只会在去出key的时候会对数据进行过期检查。
2. 定期删除：每隔一段时间抽取一批 key 执行删除过期 key 操作。



### Redis内存淘汰机制

1. **volatile-lru（least recently used）**：从已设置过期时间的数据集（`server.db[i].expires`）中挑选最近最少使用的数据淘汰。
2. **volatile-ttl**：从已设置过期时间的数据集（`server.db[i].expires`）中挑选将要过期的数据淘汰。
3. **volatile-random**：从已设置过期时间的数据集（`server.db[i].expires`）中任意选择数据淘汰。
4. **allkeys-lru（least recently used）**：当内存不足以容纳新写入数据时，在键空间中，移除最近最少使用的 key（这个是最常用的）。
5. **allkeys-random**：从数据集（`server.db[i].dict`）中任意选择数据淘汰。
6. **no-eviction**：禁止驱逐数据，也就是说当内存不足以容纳新写入数据时，新写入操作会报错。这个应该没人使用吧！

4.0 版本后增加以下两种：

1. **volatile-lfu（least frequently used）**：从已设置过期时间的数据集（`server.db[i].expires`）中挑选最不经常使用的数据淘汰。
2. **allkeys-lfu（least frequently used）**：当内存不足以容纳新写入数据时，在键空间中，移除最不经常使用的 key



## Redis 事务

Redis 事务是支持持久性的。提供了一种将多个命令请求打包的功能。然后，再按顺序执行打包的所有命令，并且不会被中途打断

1. RDB
2. AOF
3. RDB和AOF的混合持久化

**但Redis事务很少进行使用**，不满足原子性，但是支持持久性，但不保证持久性

### 如何解决Redis事务的缺陷：

Lua脚本来保证原子性。它的功能和事务非常类似。我们可以利用 Lua 脚本来批量执行多条 Redis 命令，这些 Redis 命令会被提交到 Redis 服务器一次性执行完成，大幅减小了网络开销。



## Redis 性能优化



### 批量操作

一个redis命令的执行有4步，其中发送命令和获得结果消耗的时间成为是 RTT，往返时间，也就是数据在网络上传输的时间。批量操作可以减少网络传输次数。

1. 原生批量操作
2. pipeline：利用 **pipeline（流水线)** 将一批 Redis 命令封装成一组，这些 Redis 命令会被一次性提交到 Redis 服务器，只需要一次网络传输。
3. Lua脚本



### bigkey

如果一个 key 对应的 value 所占用的内存比较大，那这个 key 就可以看作是 bigkey。  一般是string类型数据超过10kb就算



发现bigkey的方法：

1. redis自带的 bigkeys参数
2. 分析RDB文件，利用 现有的开源工具来实现



处理方法：

1. 手动清理
2. 采用合适的数据结构，比如bitmap或者hyperloglog



### hotkey

简单来说，如果一个 key 的访问次数比较多且明显多于其他 key 的话，那这个 key 就可以看作是 hotkey。

比如QTS 5000次，有2000次是这个key



**危害是什么**

处理 hotkey 会占用大量的 CPU 和带宽，可能会影响 Redis 实例对其他请求的正常处理。此外，如果突然访问 hotkey 的请求超出了 Redis 的处理能力，Redis 就会直接宕机。这种情况下，大量请求将落到后面的数据库上，可能会导致数据库崩溃。



**发现hotkey的方法是什么**

1. 自带的参数方法 hotkeys：这个命令也会增加 Redis 实例的 CPU 和内存消耗（全局扫描），因此需要谨慎使用
2. **使用`monitor` 命令**：但是这个方法对redis性能影响也很大，因为是可以实时查看redis的所有操作，可以用于临时监控 Redis 实例的操作情况，包括读写、删除等操作。
3. 可以借用开源工具，比如京东的hotkey。
4. 根据业务提取预估
5. 业务代码中记录分析



**处理方法：**

1. **读写分离**：主节点处理写请求，从节点处理读请求。
1. **使用 Redis Cluster**：将热点数据分散存储在多个 Redis 节点上。
1. **二级缓存**：hotkey 采用二级缓存的方式进行处理，将 hotkey 存放一份到 JVM 本地内存中（可以用 Caffeine）





## Redis 内存碎片

### 什么是内存碎片

将内存碎片简单地理解为那些不可用的空闲内存，Redis 内存碎片虽然不会影响 Redis 性能，但是会增加内存消耗。



### 为什么会出现Redis内存碎片

1. **Redis 存储存储数据的时候向操作系统申请的内存空间可能会大于数据实际需要的存储空间。**

   Redis 可以使用多种内存分配器来分配内存，默认使用的是jemalloc,jemalloc是按照固定大小8,16,32字节这样子来进行分配。会造成内存浪费。

2. **频繁修改 Redis 中的数据也会产生内存碎片。**



mem_fragmentation_ratio  =  实际使用的 /  内存分配出去的   如果mem_fragmentation_ratio > 1.5，则代表需要进想清理了。



### 清理Redis内存

1. Redis4.0-RC3 版本以后自带了内存整理，可以避免内存碎片率过大的问题。直接通过 `config set` 命令将 `activedefrag` 配置项设置为 `yes` 即可。
2. 重启节点可以做到内存碎片重新整理。



## 特殊的数据结构详解



### Bitmap

存储的是二进制数字，通过一个bitmap，通过一个bit来表示某个元素对应的值或者状态

**应用场景：**

用户签到情况，活跃用户情况，用户行为统计



### HyperLogLog

Redis 提供的 HyperLogLog 占用空间非常非常小，只需要 12k 的空间就能存储接近`2^64`个不同元素。

**应用场景：**

**数量量巨大（百万、千万级别以上）的计数场景**

- 举例：热门网站每日/每周/每月访问 ip 数统计、热门帖子 uv 统计





### Geospatial index

Geospatial index（地理空间索引，简称 GEO） 主要用于存储地理位置信息，基于 Sorted Set 实现。

**需要管理使用地理空间数据的场景**

- 举例：附近的人。



## Redis 持久化

一共分为三种： RDB，只追加文件AOF，混合持久化



### RDB

可以通过创建快照来获得存储在内存里面的数据在 **某个时间点** 上的副本。  RDB是**默认采用的持久化方式**



### AOF工作流程是什么

1. 命令追加：所有命令追加到AOF缓冲区中
2. 文件写入：将 AOF 缓冲区的数据写入到 AOF 文件中。
3. 文件同步：根据持久化策略用fsync向硬盘进行同步。
4. 文件重写：需要定期对 AOF 文件进行重写。

### **AOF持久化方式都有哪些**： 

1. appendfsync always：主线程调用write后，后台线程会立即调用fsync同步到AOF文件中。严重降低redis的性能
2. appendfsync everysec: 每秒钟调用 `fsync` 函数（系统调用）同步一次 AOF 文件
3. appendfsync no:让操作系统决定何时进行同步，Linux 下一般为 30 秒一次

一般会选择 appendsync everysec





### AOF为什么是在执行命令之后记录日志

1. 避免额外的检查开销，AOF 记录日志不会对命令进行语法检查；

2. 在命令执行完之后再记录，不会阻塞当前的命令执行。

所带来的的风险：

1. 如果刚执行完命令 Redis 就宕机会导致对应的修改丢失；

2. 可能会阻塞后续其他命令的执行（AOF 记录日志是在 Redis 主线程中进行的）



### AOF校验机制

AOF 校验机制是 Redis 在启动时对 AOF 文件进行检查，以判断文件是否完整，是否有损坏或者丢失的数据。这个机制的原理其实非常简单，就是通过使用一种叫做 **校验和（checksum）** 的数字来验证 AOF 文件。



### AOF重写：

会放到子线程执行

当 AOF 变得太大时，Redis 能够在后台自动重写 AOF 产生一个新的 AOF 文件，这个新的 AOF 文件和原有的 AOF 文件所保存的数据库状态一样，但体积更小。

AOF 文件重写期间，Redis 还会维护一个 **AOF 重写缓冲区**，该缓冲区会在子进程创建新 AOF 文件期间，记录服务器执行的所有写命令。当子进程完成创建新 AOF 文件的工作之后，服务器会将重写缓冲区中的所有内容追加到新 AOF 文件的末尾，使得新的 AOF 文件保存的数据库状态与现有的数据库状态一致。



### 如何选择RDB和AOF

Redis 保存的数据丢失一些也没什么影响的话，可以选择使用 RDB。

不建议单独使用 AOF，因为时不时地创建一个 RDB 快照可以进行数据库备份、更快的重启以及解决 AOF 引擎错误。

如果保存的数据要求安全性比较高的话，建议同时开启 RDB 和 AOF 持久化或者开启 RDB 和 AOF 混合持久化。



## Redis应用场景



### 购物车 信息是用String合适还是Hash存储合适



### 使用Redis实现一个排行榜怎么实现



### 怎么用Set实现抽奖系统



## Redis生产问题



### 缓存穿透

大量请求的 key 是不合理的，**根本不存在于缓存中，也不存在于数据库中** 。



解决方法：

做好参数校验，一些不合法的参数请求直接抛出异常信息返回给客户端。

1. 缓存无效key，并设置一个过期时间
2. 布隆过滤器



### 缓存击穿

缓存击穿中，请求的 key 对应的是 **热点数据** ，该数据 **存在于数据库中，但不存在于缓存中（通常是因为缓存中的那份数据已经过期）** 。这就可能会导致瞬时大量的请求直接打到了数据库上，对数据库造成了巨大的压力，可能直接就被这么多请求弄宕机了。



解决方法：

1. 设置热点数据永不过期或者过期时间比较长。

2. 针对热点数据提前预热，将其存入缓存中并设置合理的过期时间比如秒杀场景下的数据在秒杀结束之前不过期。

3. 请求数据库写数据到缓存之前，先获取互斥锁，保证只有一个请求会落到数据库上，减少数据库的压力。

   



### 缓存雪崩

**缓存在同一时间大面积的失效，导致大量的请求都直接落到了数据库上，对数据库造成了巨大的压力。**



可以理解为 缓存中大量数据同时过期。



解决方法：

1. 采用redis集群。
2. 限流
3. 设置不同的失效时间比如随机设置缓存的失效时间。
4. 设置二级缓存



### 保证缓存和数据库数据的一致性



实际上一般讲的话就是旁路缓存机制

如果更新数据库成功，而删除缓存这一步失败的情况的话，简单说两个解决方案：

1. **缓存失效时间变短（不推荐，治标不治本）**
2. **增加 cache 更新重试机制（常用）**



## 缓存思想

其本质思想就是以空间换时间





### 其他地方用到缓存的思想

1. CPU cache：解决CPU处理速度和内存的速度不匹配的问题。
2. 快表：操作系统再页表方案基础上引入快表来加速虚拟地址到物理地址的转换。



### 本地缓存的方案

本地缓存位于应用内部，其最大的优点是应用存在于同一个进程内部，请求本地缓存的速度非常快，不存在额外的网络开销。 比如说nginx来做负载均衡

**优势：低依赖、轻量、简单、成本低**

**劣势：**

- 对分布式架构不好。
- 本地缓存容量受到所在机器限制。



**JDK自带的HashMap和concurrentHashMap**

因为有key和value。但大部分场景来说不会使用这两者当做缓存，因为只提供了缓存的功能，并没有提供其他诸如过期时间之类的功能。一个稍微完善一点的缓存框架至少要提供：过期时间、淘汰机制、命中率统计这三点



**Ehcache、Guava Cache、spring cache**

- 相比于 Guava Cache 、 Spring Cache 来说， Ehcache 支持可以嵌入到 hibernate 和 mybatis 作为多级缓存，并且可以将缓存的数据持久化到本地磁盘中
- uava 相比于 Spring Cache 的话使用的更多一点，它提供了 API 非常方便我们使用，同时也提供了设置缓存有效时间等功能。它的内部实现也比较干净，很多地方都和 ConcurrentHashMap 的思想有异曲同工之妙。
- 使用 Spring Cache 的注解实现缓存的话，代码会看着很干净和优雅，但是很容易出现问题比如缓存穿透、内存溢出。



**caffeine**

与guava类似，一般用来替代guava的。





### 多级缓存

1. 本地缓存与分布式缓存的优点在于，它并不需要额外的网络开销，所以需要引入进来。
2. 但是多级缓存会增加不必要的麻烦，比如数据一致性。
3. 适合多级缓存的场景
   - 缓存的数据不经常修改，比较稳定。
   - 访问量巨大，比如秒杀。



一般使用的是，一级缓存是caffeine，二级缓存是redis

读取缓存数据的时候，我们先从 L1 中读取，读取不到的时候再去 L2 读取。这样可以降低 L2 的压力，减少 L2 的读次数。如果 L2也没有此数据的话，再去数据库查询，数据查询成功后再将数据写入到 L1 和 L2 中。





## 主从节点之间怎么同步数据

该问题有很多种类似的问题：

1. 主从复制的原理是什么
2. master节点的数据是如何同步给slave节点的
3. 复制积压缓冲区的作用



**主从服务器第一次同步流程：**

1. 发送replicaof来确定谁是主服务器谁是从服务器
2. 建立连接，协商同步
   - 从服务器会向主服务器发送`psync`表示要同步，包含有两个参数`runid` 和`offset`
   - 主服务器返回`FULLRESYNC`带上这两个参数（这里的`FULLRESYNC`指的是全量复制的意思） 
3. 主服务器同步数据给从服务器
   - 主服务器执行`BGSAVE`命令生成RDB文件，发送给从服务器（不会阻塞主线程，是在子线程完成的，异步）注意在生成RDB期间，主服务器还是在工作的，这期间的所有命令都会写入replication buffer中（会写进来的有3种情况）
     - 主服务器生成RDB文件
     - 主服务器发送RDB文件给从服务器期间
     - 从服务器加载RDB期间
   - 从服务器收到RDB文件后，清空现有数据，载入RDB文件
4. 主服务器发送新写操作命令给从服务器
   - 从服务器数据载入RDB完成后，回复一个确认给主服务器
   - 将`replication buffer`所有的写操作发送给你从服务器。

**完成第一次同步。**



完成第一次同步后，二者之间会建立一个TCP连接来维持并进行更新。

在主服务器进行命令传播时，不仅会将写命令发送给从服务器，还会将写命令写入到 复制积压缓冲区里，因此 这个复制积压缓冲区里会保存着最近传播的写命令。



如果发生断网后服务后，Redis将采用增量复制的方法进行同步，具体操作如下：

1. 从服务器会通过`psync`将自己的复制偏移量发送给主服务器。
2. 主服务器接收到后就会和自己的偏移量进行比对。
   - 如果读取的数据还在复制积压缓冲区中，则增量同步。
   - 如果不在，则全量同步。

**为了避免在网络恢复时，主服务器频繁地使用全量同步的方式，我们应该调整下 repl_backlog_buffer 缓冲区大小，尽可能的大一些**



### **为什么主从全量复制使用 RDB 而不是 AOF？**

题其实本质是在对比 RDB 和 AOF 这两种持久化方式。

- RDB 文件存储的内容是经过压缩的二进制数据，文件很小。AOF 文件存储的是每一次写命令，类似于 MySQL 的 binlog 日志，通常会比 RDB 文件大很多。因此，传输 RDB 文件更节省带宽，速度也更快。
- 使用 RDB 文件恢复数据，直接解析还原数据即可，不需要一条一条地执行命令，速度非常快。而 AOF 则需要依次执行每个写命令，速度非常慢。也就是说，与 AOF 相比，恢复大数据集的时候，RDB 速度更快。
- AOF 需要选择合适的刷盘策略，如果刷盘策略选择不当的话，会影响 Redis 的正常运行。并且，根据所使用的刷盘策略，AOF 的速度可能会慢于 RDB。



## Redis sentinel

1. 监控：监控所有的master和slave的状态是否正常
2. 故障转移：如果一个master出现故障，sentinel就会帮我们实现故障转移。
3. 通知：通知slave关于新的master信息，让他们执行replicaof成为新的master的slave。
4. 配置提供：通知关于新的master的地址。

**sentinel的高可用性体现在多个sentinel节点通过投票来确定节点是否可用，避免误判。**

**哨兵节点之间是通过 Redis 的发布者/订阅者机制来相互发现的**。



### Redis sentinel检测节点下线

有两个概念：

1. 主观下线：sentinel节点认为redis节点已经下线。
2. 客观下线：sentinel集体表决认为redis节点已经下线。

每个 sentinel 节点以每秒钟一次的频率向整个集群中的 master、slave 以及其他 sentinel 节点发送一个 PING 命令。

slave下线无所谓，sentinel主要关心的是master的下线。所有 sentinel 节点要以每秒一次的频率确认 master 的确下线了，当法定数量（通常为过半）的 sentinel 节点认定 master 已经下线， master 才被判定为 客观下线(ODOWN) 。



sentinel 中会有一个 Leader 的角色来负责故障转移，也就是自动地从 slave 中选出一个新的 master 并执行完相关的一些工作

- 同时slave新的master的信息等等，让他们进行replicaof



### Redis sentinel集群中选择出Leader

通过这个Leader来完成故障转移。使用的方法是Raft





### 故障转移全过程

1. **在旧的master所属下的所有slave中，挑选一个节点转化为master。**
   - 把网络不好的节点给删除：redis里边有一个是down-after-milliseconds，这个时间是没有回复的时间，就认为是主从节点断连。如果发生断连的次数超过了 10 次，就说明这个从节点的网络状况不好，不适合作为新主节点。
   - 优先级排序：Redis 有个叫 slave-priority 配置项，可以给从节点设置优先级。
   - 优先级相同的话，看复制数据的下标，复制越多，优先级越靠前。
   - 如果都一样，就选节点ID小的那个。

​		在选举出从节点后，哨兵 leader 向被选中的从节点发送 `SLAVEOF no one` 命令，让这个从节点解除从节点的身份，将其变为新主节点。

2. **将从节点指向新主节点：**让已下线主节点属下的所有「从节点」指向「新主节点」，这一动作可以通过向「从节点」发送 `SLAVEOF` 命令来实现。
3. **通知客户的主节点已更换：** 主要通过 Redis 的发布者/订阅者机制来实现的。每个哨兵节点提供发布者/订阅者机制，客户端可以从哨兵订阅消息。
4. **将旧主节点变为从节点：** 



## Redis Cluster



### 为什么需要Redis Cluster？解决了什么问题？有什么优势？

1. 缓存的数据集太大：实际的缓存数据量达到几十个G甚至成百上千个G
2. 并发量要求太大：虽然 Redis 号称单机可以支持 10w 并发，但实际项目中，不可靠因素太多，就比如一些复杂的写/读操作就可能会让这个并发量大打折扣。而且在一些大型的项目中，10w并发量很容易到达瓶颈。



主从复制和 Redis Sentinel 这两种方案本质都是通过增加主库（master）的副本（slave）数量的方式来提高 Redis 服务的整体可用性和读吞吐量，都不支持横向扩展来缓解写压力以及解决缓存数据量过大的问题。



**redis cluster的意思是** 部署多台 Redis 主节点（master），这些节点之间平等，并没有主从之说，同时对外提供读/写服务。缓存的数据库相对均匀地分布在这些 Redis 实例上，客户端的请求通过路由规则转发到目标 master 上。



**redis cluster的优势：**

- 可以横向扩展缓解写压力和存储压力，支持动态扩容和缩容；
- 具备主从复制、故障转移（内置了 Sentinel 机制，无需单独部署 Sentinel 集群）等开箱即用的功能。



### 一个最基本的 Redis Cluster 架构是怎样的？

为了保证高可用，Redis Cluster 至少需要 3 个 master 以及 3 个 slave，也就是说每个 master 必须有 1 个 slave。master 和 slave 之间做主从复制，slave 会实时同步 master 上的数据。



Redis Cluster 是去中心化的（各个节点基于 Gossip 进行通信），任何一个 master 出现故障，其它的 master 节点不受影响，因为 key 找的是哈希槽而不是 Redis 节点。



### Redis cluster是如何分片的

重要问题：

- RedisCluster 中的数据是如何分布的？
- 如何确定给定 key 的应该分布到哪个哈希槽中？



**哈希槽的计算方法：**

Redis Cluster 并没有使用一致性哈希，采用的是 **哈希槽分区** ，每一个键值对都属于一个 **hash slot（哈希槽）**，Redis Cluster有 2^14个哈希槽

要计算给定 key 应该分布到哪个哈希槽中，我们只需要先对每个 key 计算 CRC-16校验码，然后再对这个校验码对 16384(哈希槽的总数) 取模，得到的值即是 key 对应的哈希槽。



**具体流程是：**

客户端连接 Redis Cluster 中任意一个 master 节点即可访问 Redis Cluster 的数据，当客户端发送命令请求的时候，需要先根据 key 通过上面的计算公示找到的对应的哈希槽，然后再查询哈希槽和节点的映射关系，即可找到目标节点。



### 为什么哈希槽数量是2^14

CRC16 算法产生的校验码有 16 位，理论上可以产生 2^16个值。为什么 Redis Cluster 的哈希槽偏偏选择的是 2^14个呢？

- 正常的心跳包会携带一个节点的完整配置，它会以幂等的方式更新旧的配置，这意味着心跳包会附带当前节点的负责的哈希槽的信息。假设哈希槽采用 16384 ,则占空间 2k(16384/8)。假设哈希槽采用 65536， 则占空间 8k(65536/8)，这是令人难以接受的内存占用。
- 由于其他设计上的权衡，Redis Cluster 不太可能扩展到超过 1000 个主节点。



在redis中，是利用bitmap来维护哈希槽信息。每一个 bit 代表一个哈希槽，每个 bit 只能存储 0/1 。如果该位为 1，表示这个哈希槽是属于这个节点。



总结而说就是：

- 哈希槽太大会导致心跳包太大，消耗太多带宽；
- 哈希槽总数越少，对存储哈希槽信息的 bitmap 压缩效果越好；
- Redis Cluster 的主节点通常不会扩展太多，16384 个哈希槽已经足够用了。



### Redis cluster扩容期间可以提供服务吗

**Redis Cluster 扩容和缩容本质是进行重新分片，动态迁移哈希槽。** 为了保证扩容期间的可用性，redis cluster有两个机制：

- ASK 重定向 ：可以看做是临时重定向，后续查询仍然发送到旧节点。
- MOVED 重定向 ：可以看做是永久重定向，后续查询发送到新节点。



### Redis Cluster中的节点是怎么进行通信的

Redis Cluster 中的各个节点基于 Gossip 协议 来进行通信共享信息，每个 Redis 节点都维护了一份集群的状态信息。



Redis Cluster 的节点之间会相互发送多种 Gossip 消息：

- **MEET：** 将节点添加进redis cluster中
- **PING/PONG ：**Redis Cluster 中的节点都会定时地向其他节点发送 PING 消息，来交换各个节点状态信息，检查各个节点状态，包括在线状态、疑似下线状态 PFAIL 和已下线状态 FAIL。
- **FAIL ：**Redis Cluster 中的节点 A 发现 B 节点 PFAIL ，并且在下线报告的有效期限内集群中半数以上的节点将 B 节点标记为 PFAIL，节点 A 就会向集群广播一条 FAIL 消息，通知其他节点将故障节点 B 标记为 FAIL 



## Redis常见阻塞原因



### O(n)命令

有一些命令是On命令，随着数据越多，执行耗时也会越长。



### SAVE创建RDB快照

redis有两个命令可以执行RDB

1. `SAVE`同步保存操作，会阻塞redis主线程
2. `bsave` fork一个子线程，然后子线程执行，不会阻塞主线程。

默认情况下，Redis 默认配置会使用 `bgsave` 命令。如果手动使用 `save` 命令生成 RDB 快照文件的话，就会阻塞主线程。



### AOF日志记录阻塞

AOF重写缓冲区的所有内容追加到新的AOF文件末尾时会产生阻塞。



### 大Key

1. 客户端超时
2. 网络IO超时
3. 阻塞工作线程：使用del删除大key



### 删除大Key

删除操作的本质是要释放键值对占用的内存空间。

释放内存只是第一步，为了更加高效地管理内存空间，在应用程序释放内存时，**操作系统需要把释放掉的内存块插入一个空闲内存块的链表**，以便后续进行管理和再分配。这个过程本身就会阻塞线程工作



删除大 key 时建议采用分批次删除和异步删除的方式进行。



### 集群扩容

在扩缩容的时候，需要进行数据迁移。而 Redis 为了保证迁移的一致性，迁移所有操作都是同步操作。

执行迁移时，两端的 Redis 均会进入时长不等的阻塞状态，对于小 Key，该时间可以忽略不计，但如果一旦 Key 的内存使用过大，严重的时候会触发集群内的故障转移，造成不必要的切换。



### Swap（内存交互）

Redis 保证高性能的一个重要前提是所有的数据在内存中。如果操作系统把 Redis 使用的部分内存换出硬盘，由于内存与硬盘读写的速度并几个数量级，会导致发生交换后的 Redis 性能急剧下降。



### 网络问题



### CPU竞争



## Redis 锁

