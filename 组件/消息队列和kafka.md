### 消息队列的作用是什么？

1. 通过异步处理提高系统性能。
2. 削峰/限流
3. 降低系统的耦合性



### AMQP是什么？

是一种提供统一消息服务的应用层标准的消息队列协议。基于此协议的客户端与消息中间件可传递消息，并不受客户端/中间件同产品，不同的开发语言等条件的限制





### Kafka的两大应用场景

1. 消息队列：建立实时流数据通道。
2. 数据处理：可以构建实时的流数据处理程序来转换或处理数据流。



### 和其他的消息队列相对，kafka的优势在哪？

1. **极致的性能：**基于 Scala 和 Java 语言开发，设计中大量使用了批量处理和异步的思想，最高可以每秒处理千万级别的消息。
2. **生态系统兼容性好：**



### 队列模型和发布-订阅模型的区别是什么

使用队列作为消息通信的载体，一条消息只能被一个消费者使用。



发布订阅模型使用的是 **主题**作为消息通信的载体，类似于广播模式，只有订阅的人才能收到。



### Kafka的概念

1. 生产者
2. 消费者
3. 代理：可以看作是一个独立的kafka的实例。每个broker又包含有2个重要的概念
   - Topic：Producer发布主题，consumer订阅主题。
   - Partition：对应于消息队列中的队列。 一个Topic可以有多个Partition，一个Topic有多个broker。



### Kafka的多副本机制了解吗

分区（Partition）中的多个副本之间会有一个叫做 leader 的家伙，其他副本称为 follower。我们发送的消息会被发送到 leader 副本，然后 follower 副本才能从 leader 副本中拉取消息进行同步。

生产者和消费者只与Leader副本交互。它们的存在只是为了保证消息存储的安全性。



**存在的好处**

1. Kafka 通过给特定 Topic 指定多个 Partition, 而各个 Partition 可以分布在不同的 Broker 上, 这样便能提供比较好的并发能力。
2. Partition 可以指定对应的 Replica 数, 这也极大地提高了消息存储的安全性, 提高了容灾能力。



### Zookeeper在Kakfa中的作用是什么？

1. **Broker的注册：**有一个节点专门用来进行Broker服务器记录的节点。当Broker启动后，都会到zookeeper上注册。
2. **Topic注册：**在 Kafka 中，同一个**Topic 的消息会被分成多个分区**并将其分布在多个 Broker 上，**这些分区信息及与 Broker 的对应关系**也都是由 Zookeeper 在维护。
3. **负载均衡**



### Kafka如何保证消息的消费顺序

每次添加消息到 Partition(分区) 的时候都会采用尾加法，即使用一个偏移量。 **Kafka 只能为我们保证 Partition(分区) 中的消息有序。**因此，我们可以用：

1. 1个 Topic 只对应一个 Partition。
2. （推荐）发送消息的时候指定 key/Partition。



### Kafka如何保证消息不丢失



#### 生产者丢失消息的情况

发送`send`后，因为网络问题没有发送过去。可以使用生产者的重试机制。



####  消费者丢失消息的情况

当消费者拉取到了某个分区的某个消息后，消费者会自动提交offset，但这里会出问题，就是拿到后消费者就会挂掉。那么就可以关闭自动提交offset，每次真正消费完消息后再手动提交offset。



#### Kafka弄丢了消息

kafka对于这个问题有3个参数

1. **acks**：默认值为1，表示如果leader副本接收后就算成功发送。 如果配置acks=all表示所有ISR列表的副本全部收到消息后，生产者才会接收到来自服务器的响应.。
2. **设置 replication.factor >= 3**：保证每个 分区(partition) 至少有 3 个副本
3. 



### 如何保证消息不重复消费

**kafka 出现消息重复消费的原因：**

1. 服务端侧已经消费的数据没有成功提交 offset（根本原因）。
2. Kafka 侧 由于服务端处理业务时间长或者网络链接等等原因让 Kafka 认为服务假死，触发了分区 rebalance。



**解决办法：**

1. 最佳方法：消费消息服务做幂等校验，比如Redis的Set，MySQL的主键等天然的幂等功能。
2. 关闭自动提交offset功能。那么什么时候开启是最好的？
   - 处理完消息再提交：依旧有消息重复消费的风险，和自动提交一样
   - 拉取到消息即提交：会有消息丢失的风险。允许消息延时的场景，一般会采用这种方式。



###  kafka的主从机制描述下

