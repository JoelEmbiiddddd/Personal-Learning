## CPU 缓存一致性



CPU分为三级缓存，L1和L2是每个核心各自都有的，L3是所有核心共享使用的。





## 零拷贝



### 为什么需要DMA技术

在DMA以前，I/O的过程是 CPU发出对应的指令给磁盘控制器，然后 磁盘控制器会把数据准备好放入到自己的内存缓存区中，然后产生一个中断。 CPU收到中断后，就会停下手头的工作，把磁盘缓存区中的数据一个一个读入到自己的寄存器中，读完后再写入到内存中。 而这个期间CPU是什么事情都干不了了。



### DMA是什么

**在进行 I/O 设备和内存的数据传输的时候，数据搬运的工作全部交给 DMA 控制器，而 CPU 不再参与任何与数据搬运相关的事情，这样 CPU 就可以去处理别的事务**。



具体过程

1. 用户进程发出I/O请求，将数据读取到自己的用户缓冲区中，进入阻塞状态。
2. 操作系统收到命令后，将I/O发送到DMA中，然后让CPU执行其他任务。
3. DMA将I/O请求发送给磁盘。
4. 磁盘将数据读入到磁盘缓冲区后，告知DMA已经读取完成。
5. DMA收到磁盘的信号后，将数据拷贝到内核缓冲区中。
6. 读取完成后，就告知CPU过来取。
7. CPU就从内核拷贝到用户空间中。

现在基本上每个I/O设备里面都有自己的DMA控制器



### 为什么要对文件传输进行优化（为何要实现零拷贝）

1. 传统的文件传输涉及到了4次用户态与内核态的上下文切换，而上下文切换成本很高。
2. 同时还发生了4次数据拷贝。



所以我们应该提高文件传输的性能，减少 **用户态和内核态**的上下文切换和**内存拷贝**的次数。



### mmap + write

在系统调用read，会把内核缓冲区的数据拷贝到用户缓冲区中。于是为了减少这一步开支，可以用 mmap 替换read。

mmap会直接把内核缓冲区里的数据映射到用户空间中，这样 操作系统内核与用户空间就不需要进行任何的数据拷贝操作了。



而且仍然需要 4 次上下文切换，因为系统调用还是 2 次



### sendfile

可以直接把内核缓冲区的数据拷贝到socket缓冲区中，不再拷贝到用户态中。

主题的流程就是：

1. DMA将磁盘上的数据拷贝到内核缓冲区中。
2. 缓冲区描述符和数据长度传到 socket 缓冲区，这样网卡的 SG-DMA 控制器就可以直接将内核缓存中的数据拷贝到网卡的缓冲区里。

整个过程只涉及到2次数据拷贝。



### 什么是零拷贝，优点是什么？

因为我们没有在内存层面去拷贝数据，也就是说全程没有通过 CPU 来搬运数据，所有的数据都是通过 DMA 来进行传输的。



零拷贝技术的文件传输方式相比传统文件传输的方式，减少了 2 次上下文切换和数据拷贝次数，**只需要 2 次上下文切换和数据拷贝次数，就可以完成文件的传输，而且 2 次的数据拷贝过程，都不需要通过 CPU，2 次都是由 DMA 来搬运。**



### 使用了零拷贝的项目

1. kafka用到了 sendfile() 函数，提升了 I/O 的吞吐率。这也是 Kafka 在处理海量数据为什么这么快的原因之一。
2. Nginx也支持零拷贝技术。



### PageCache

PageCache 实际上就是 从磁盘拷贝到内存缓冲区，这个内存缓冲区就是 PageCache。

在实际应用中，发现 内存不能够完全把磁盘中的数据拷贝到内存中。那么，选择把哪些磁盘数据拷贝到内存中很重要？

所以用 **PageCache 来缓存最近被访问的数据**，当空间不足时淘汰最久未被访问的缓存。所以，读磁盘数据的时候，优先在 PageCache 找，如果数据存在则可以直接返回；如果没有，则从磁盘中读取，然后缓存 PageCache 中。



PageCache还有一个 **预读功能** ， 也就是 除了读取实际需要的数据，还会把后面的数据也一起读取进pagecache中

所以，PageCache 的优点主要是两个：

- 缓存最近被访问的数据；
- 预读功能；





### 为什么大文件（GB级别的文件） PageCache不会起作用？

1. 文件太多，很快就会把PageCache给填满。
2. 而且，由于文件太大了，部分文件数据被再次访问的概率会很低。



所以针对大文件传输，不应该用pageCache，也就是零拷贝。

因为可能由于 PageCache 被大文件占据，而导致「热点」小文件无法利用到 PageCache，这样在高并发的环境下，会带来严重的性能问题。



### 大文件如何传输，用什么实现

**在高并发的场景下，针对大文件的传输的方式，应该使用「异步 I/O + 直接 I/O」来替代零拷贝技术**。也就是绕开PageCache直接读取文件。



使用PageCache的是缓存I/O



### 直接I/O的两个场景

- 应用程序已经实现了磁盘数据的缓存，那么可以不需要 PageCache 再次缓存，减少额外的性能损耗。在 MySQL 数据库中，可以通过参数设置开启直接 I/O，默认是不开启；
- 传输大文件的时候，由于大文件难以命中 PageCache 缓存，而且会占满 PageCache 导致「热点」文件无法充分利用缓存，从而增大了性能开销，因此，这时应该使用直接 I/O。





## I/O多路复用



### 为什么不用进程管理

上下文切换消耗的资源太大



### 为什么不用线程管理

如果每来一个连接就创建一个线程，线程运行完后，还得操作系统还得销毁线程，虽说线程切换的上写文开销不大，但是如果频繁创建和销毁线程，系统开销也是不小的。





### I/O多路复用

用一个进程来维护多个Socket，就是I/O多路复用。 使用的方式就是，一个进程虽然任一时刻只能处理一个进程，但我处理每个进程控制在1毫秒以内。 1秒钟就能处理上千个请求。 这种思想就类似于 cpu并发多个进程，时分多路复用。



### selec实现多路复用的方法

