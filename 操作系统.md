## CPU 缓存一致性



CPU分为三级缓存，L1和L2是每个核心各自都有的，L3是所有核心共享使用的。





## 零拷贝



### 为什么需要DMA技术

在DMA以前，I/O的过程是 CPU发出对应的指令给磁盘控制器，然后 磁盘控制器会把数据准备好放入到自己的内存缓存区中，然后产生一个中断。 CPU收到中断后，就会停下手头的工作，把磁盘缓存区中的数据一个一个读入到自己的寄存器中，读完后再写入到内存中。 而这个期间CPU是什么事情都干不了了。



### DMA是什么

**在进行 I/O 设备和内存的数据传输的时候，数据搬运的工作全部交给 DMA 控制器，而 CPU 不再参与任何与数据搬运相关的事情，这样 CPU 就可以去处理别的事务**。



具体过程

1. 用户进程发出I/O请求，将数据读取到自己的用户缓冲区中，进入阻塞状态。
2. 操作系统收到命令后，将I/O发送到DMA中，然后让CPU执行其他任务。
3. DMA将I/O请求发送给磁盘。
4. 磁盘将数据读入到磁盘缓冲区后，告知DMA已经读取完成。
5. DMA收到磁盘的信号后，将数据拷贝到内核缓冲区中。
6. 读取完成后，就告知CPU过来取。
7. CPU就从内核拷贝到用户空间中。

现在基本上每个I/O设备里面都有自己的DMA控制器



### 为什么要对文件传输进行优化（为何要实现零拷贝）

1. 传统的文件传输涉及到了4次用户态与内核态的上下文切换，而上下文切换成本很高。
2. 同时还发生了4次数据拷贝。



所以我们应该提高文件传输的性能，减少 **用户态和内核态**的上下文切换和**内存拷贝**的次数。



### mmap + write

在系统调用read，会把内核缓冲区的数据拷贝到用户缓冲区中。于是为了减少这一步开支，可以用 mmap 替换read。

mmap会直接把内核缓冲区里的数据映射到用户空间中，这样 操作系统内核与用户空间就不需要进行任何的数据拷贝操作了。



而且仍然需要 4 次上下文切换，因为系统调用还是 2 次



### sendfile

可以直接把内核缓冲区的数据拷贝到socket缓冲区中，不再拷贝到用户态中。

主题的流程就是：

1. DMA将磁盘上的数据拷贝到内核缓冲区中。
2. 缓冲区描述符和数据长度传到 socket 缓冲区，这样网卡的 SG-DMA 控制器就可以直接将内核缓存中的数据拷贝到网卡的缓冲区里。

整个过程只涉及到2次数据拷贝。



### 什么是零拷贝，优点是什么？

因为我们没有在内存层面去拷贝数据，也就是说全程没有通过 CPU 来搬运数据，所有的数据都是通过 DMA 来进行传输的。



零拷贝技术的文件传输方式相比传统文件传输的方式，减少了 2 次上下文切换和数据拷贝次数，**只需要 2 次上下文切换和数据拷贝次数，就可以完成文件的传输，而且 2 次的数据拷贝过程，都不需要通过 CPU，2 次都是由 DMA 来搬运。**



### 使用了零拷贝的项目

1. kafka用到了 sendfile() 函数，提升了 I/O 的吞吐率。这也是 Kafka 在处理海量数据为什么这么快的原因之一。
2. Nginx也支持零拷贝技术。



### PageCache

PageCache 实际上就是 从磁盘拷贝到内存缓冲区，这个内存缓冲区就是 PageCache。

在实际应用中，发现 内存不能够完全把磁盘中的数据拷贝到内存中。那么，选择把哪些磁盘数据拷贝到内存中很重要？

所以用 **PageCache 来缓存最近被访问的数据**，当空间不足时淘汰最久未被访问的缓存。所以，读磁盘数据的时候，优先在 PageCache 找，如果数据存在则可以直接返回；如果没有，则从磁盘中读取，然后缓存 PageCache 中。



PageCache还有一个 **预读功能** ， 也就是 除了读取实际需要的数据，还会把后面的数据也一起读取进pagecache中

所以，PageCache 的优点主要是两个：

- 缓存最近被访问的数据；
- 预读功能；





### 为什么大文件（GB级别的文件） PageCache不会起作用？

1. 文件太多，很快就会把PageCache给填满。
2. 而且，由于文件太大了，部分文件数据被再次访问的概率会很低。



所以针对大文件传输，不应该用pageCache，也就是零拷贝。

因为可能由于 PageCache 被大文件占据，而导致「热点」小文件无法利用到 PageCache，这样在高并发的环境下，会带来严重的性能问题。



### 大文件如何传输，用什么实现

**在高并发的场景下，针对大文件的传输的方式，应该使用「异步 I/O + 直接 I/O」来替代零拷贝技术**。也就是绕开PageCache直接读取文件。



使用PageCache的是缓存I/O



### 直接I/O的两个场景

- 应用程序已经实现了磁盘数据的缓存，那么可以不需要 PageCache 再次缓存，减少额外的性能损耗。在 MySQL 数据库中，可以通过参数设置开启直接 I/O，默认是不开启；
- 传输大文件的时候，由于大文件难以命中 PageCache 缓存，而且会占满 PageCache 导致「热点」文件无法充分利用缓存，从而增大了性能开销，因此，这时应该使用直接 I/O。





## I/O多路复用



### 为什么不用进程管理

上下文切换消耗的资源太大



### 为什么不用线程管理

如果每来一个连接就创建一个线程，线程运行完后，还得操作系统还得销毁线程，虽说线程切换的上写文开销不大，但是如果频繁创建和销毁线程，系统开销也是不小的。





### I/O多路复用

用一个进程来维护多个Socket，就是I/O多路复用。 使用的方式就是，一个进程虽然任一时刻只能处理一个进程，但我处理每个进程控制在1毫秒以内。 1秒钟就能处理上千个请求。 这种思想就类似于 cpu并发多个进程，时分多路复用。



### selec实现多路复用的方法



## 什么是虚拟内存？ Linux使用的是哪种内存惯例方式



### 什么是虚拟内存

可以引申单片机，单片机内存是没办法同时运行两个程序的。  因为单片机使用的是绝对物理地址。可以把进程所使用的地址「隔离」开来，即让操作系统为每个进程分配独立的一套「**虚拟地址**」，人人都有，大家自己玩自己的地址就行，互不干涉。**操作系统会提供一种机制，将不同进程的虚拟地址和不同内存的物理地址映射起来。**



### 内存分段

**不同的段是有不同的属性的，所以就用分段（\*Segmentation\*）的形式把这些段分离出来。** 分段机制下的虚拟地址由两部分组成，**段选择因子**和**段内偏移量**。

- 段选择因子放在寄存器中，保存最重要的是短号
- 段偏移因子加段基地址就可以得到真实地址。



**存在的问题：**

- 第一个就是**内存碎片**的问题。
- 第二个就是**内存交换的效率低**的问题。**如果内存交换的时候，交换的是一个占内存空间很大的程序，这样整个机器都会显得卡顿。**



### 内存分页

分段的好处就是能产生连续的内存空间，但是会出现「外部内存碎片和内存交换的空间太大」的问题。

**分页是把整个虚拟和物理内存空间切成一段段固定尺寸的大小**

虚拟地址与物理地址之间通过**页表**来映射，**页表**是存储在内存里的，**内存管理单元** （*MMU*）就做将虚拟内存地址转换成物理地址的工作。



流程步骤：

- 把虚拟内存地址，切分成页号和偏移量；
- 根据页号，从页表里面，查询对应的物理页号；
- 直接拿物理页号，加上前面的偏移量，就得到了物理内存地址。



单简单的分页存在有缺陷，就是操作系统可以同时运行多个进程，每个页都需要花空间来存储页表项，那么就需要很大的空间来存储这些页表项。



**多级页表**

设立一级页表，一级页表下再设立二级页表。

虽然看着二级页表占用的空间更多了，但是我们往往不会为一个进程分配那么多内存。这是因为局部性原理。**如果某个一级页表的页表项没有被用到，也就不需要创建这个页表项对应的二级页表了，即可以在需要时才创建二级页表**



**TLB**

多级页表虽然解决了空间上的问题，但是虚拟地址到物理地址的转换就多了几道转换的工序，这显然就降低了这俩地址转换的速度，也就是带来了时间上的开销。

我们可以把最常访问的几个页表项存储到访问速度更快的硬件，也就是Cache。它封装了内存管理单元（*Memory Management Unit*）芯片，它用来完成地址转换和 TLB 的访问与交互。



Linux 系统中虚拟空间分布可分为**用户态**和**内核态**两部分，二者可以分开。**Linux内存使用的是页式内存管理**





**虚拟内存的作用**

- 第一，虚拟内存可以使得进程对运行内存超过物理内存大小，因为程序运行符合局部性原理，CPU 访问内存会有很明显的重复访问的倾向性，对于那些没有被经常使用到的内存，我们可以把它换出到物理内存之外，比如硬盘上的 swap 区域。
- 第二，由于每个进程都有自己的页表，所以每个进程的虚拟内存空间就是相互独立的。进程也没有办法访问其他进程的页表，所以这些页表是私有的，这就解决了多进程之间地址冲突的问题。
- 第三，页表里的页表项中除了物理地址之外，还有一些标记属性的比特，比如控制一个页的读写权限，标记该页是否存在等。在内存访问方面，操作系统提供了更好的安全性。



## 什么是malloc，和New的区别是什么

**new** 的功能是在堆区新建一个对象，并返回该对象的指针。

而**malloc** 只是机械的分配一块虚拟内存空间，如果用mallco 在堆区创建一个对象的话，是不会调用构造函数的。



## 内存管理



### 内存分配的全过程

1. 应用程序通过malloc函数申请内存。CPU读了malloc申请的虚拟内存，发现没有，就是产生缺页中断。进程会从用户态切换到内核态，并将缺页中断交给内核的 Page Fault Handler （缺页中断函数）处理。
2. 缺页中断处理函数就会看看有没有空闲的物理内存，有的话就分配，并将物理内存和虚拟内存建立联系，没有的话，内核就进行内存回收。
   - **后台内存回收**（kswapd）：在物理内存紧张的时候，会唤醒 kswapd 内核线程来回收内存，这个回收内存的过程**异步**的，不会阻塞进程的执行。
   - **直接内存回收**（direct reclaim）：如果后台异步回收跟不上进程内存申请的速度，就会开始直接回收，这个回收内存的过程是**同步**的，会阻塞进程的执行。
3. 如果直接内存回收后，空闲的物理内存仍然无法满足此次物理内存的申请，那么内核就会放最后的大招了 ——**触发 OOM （Out of Memory）机制**。
   - OOM Killer 机制会根据算法选择一个占用物理内存较高的进程，然后将其杀死，以便释放内存资源，如果物理内存依然不足，OOM Killer 会继续杀死占用物理内存较高的进程，直到释放足够的内存位置。



### 可以被回收的内存类型

1. **文件页**：内核缓存的磁盘数据（Buffer）和内核缓存的文件数据（Cache）。
2. **匿名页：** 这部分内存没有实际载体，不像文件缓存有硬盘文件这样一个载体，比如堆、栈数据等。因为有可能会再次访问，所以不能直接删除，**回收的方式是通过 Linux 的 Swap 机制**，Swap 会把不常访问的内存先写到磁盘中，然后释放这些内存，给其他更需要的进程使用。



### 如何保护一个进程不被OOM杀掉？

如何确定OOM杀掉哪些进程？

在 Linux 内核里有一个 `oom_badness()` 函数，它会把系统中可以被杀掉的进程扫描一遍，并对每个进程打分，得分最高的进程就会被首先杀掉。

- 进程已经使用的物理内存页面数。
- 每个进程的 OOM 校准值。可以通过配置文件来配置的。



### 如果4GB的内存，应用程序申请8GB的会怎么样

1. 32位系统会报错，因为它指运行一个进程申请3G的内存
2. 64位系统不会报错，因为它最多运行申请128TB的虚拟内存空间。

主要因为它分配的并不是物理内存，而是虚拟内存。



### 如何避免预读失效和缓存污染问题



#### 什么是预读机制？

我们这里可以举Linux和MySQL的缓存

**Linux的缓存机制中，会将文件读取后，放在Page Cache中,而文件的读取不是应用程序想读取多少我们给多少，而是在应用程序要求的基础上，Linux还会额外读取与它邻接的块**

**MySQL的缓存机制中，则是设计了一个Buffer Pool。MySQL Innodb 存储引擎的 Buffer Pool 也有类似的预读机制，MySQL 从磁盘加载页时，会提前把它相邻的页一并加载进来，目的是为了减少磁盘 IO**



#### 什么是预读失效？

如果**这些被提前加载进来的页，并没有被访问**，相当于这个预读工作是白做了，这个就是**预读失效**。



**如何避免：**

最好就是**让预读页停留在内存里的时间要尽可能的短，让真正被访问的页才移动到 LRU 链表的头部，从而保证真正被读取的热数据留在内存里的时间尽可能长**。

对LRU算法进行改造

1. Linux实现了两个LRU链表： 活跃LRU链表，非活跃LRU链表
2. MySQL的Innodb存储引擎是在一个LRU 链表上划分来 2 个区域：**young 区域 和 old 区域**

这两个改进方式，设计思想都是类似的，**都是将数据分为了冷数据和热数据，然后分别进行 LRU 算法**。不再像传统的 LRU 算法那样，所有数据都只用一个 LRU 算法管理。



#### 什么是缓存污染

1. 当我们在批量读取数据的时候，由于数据被访问了一次，这些大量数据都会被加入到「活跃 LRU 链表」里，然后之前缓存在活跃 LRU 链表（或者 young 区域）里的热点数据全部都被淘汰了，**如果这些大量的数据在很长一段时间都不会被访问的话，那么整个活跃 LRU 链表（或者 young 区域）就被污染了**。
2. 当某一个 SQL 语句**扫描了大量的数据**时，在 Buffer Pool 空间比较有限的情况下，可能会将 **Buffer Pool 里的所有页都替换出去，导致大量热数据被淘汰了**，等这些热数据又被再次访问的时候，由于缓存未命中，就会产生大量的磁盘 I/O，MySQL 性能就会急剧下降。



**如何避免：**

提高进入活跃LRU链表的门槛

1. **Linux 操作系统**：在内存页被访问**第二次**的时候，才将页从 inactive list 升级到 active list 里。
2. **MySQL Innodb**：在内存页被访问**第二次**的时候，并不会马上将该页从 old 区域升级到 young 区域，因为还要进行**停留在 old 区域的时间判断**：
   - 如果第二次的访问时间与第一次访问的时间**在 1 秒内**（默认值），那么该页就**不会**被从 old 区域升级到 young 区域；
   - 如果第二次的访问时间与第一次访问的时间**超过 1 秒**，那么该页就**会**从 old 区域升级到 young 区域；



### 进程虚拟内存的管理

