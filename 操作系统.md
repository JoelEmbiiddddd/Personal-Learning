## CPU 缓存一致性



CPU分为三级缓存，L1和L2是每个核心各自都有的，L3是所有核心共享使用的。



## 基础概念

### 阻塞I/O

指的是当用户程序执行read的时候，线程会被阻塞，直到这个任务完成为止。



### 非阻塞I/O

执行read的时候，就可以在这个未完成的情况下立即返回，往下执行任务。应用程序不断进行轮询，查看这个read调用是否已经完成，数据就绪。在最后一次从内核态拷贝到用户态是需要阻塞的。



### 异步I/O

和非阻塞I/O的流程类似，但是最后一次拷贝过程并不会发生阻塞现象。而是自动完成。



## 零拷贝

零拷贝从操作系统角度，是没有`cpu`拷贝。零拷贝的技术有`mmap(内存映射)`和`sendFile`



我们说零拷贝，是从操作系统的角度来说的。因为内核缓冲区之间，没有数据是重复的(只有`kernel buffer`有一份数据)。

零拷贝不仅仅带来更少的数据复制，还能带来其他的性能优势，例如更少的上下文切换，更少的`CPU`缓存伪共享以及无`CPU`校验和计算。

### mmap和sendFile的区别

1. `mmap`适合小数据量读写，`sendFile`适合大文件传输。
2. `mmap`需要`4`次上下文切换，`3`次数据拷贝；`sendFile`需要`3`次上下文切换，最少`2`次数据拷贝。
3. `mmap`可以利用`DMA`方式，减少`CPU`拷贝，`sendfile`则不能(必须从内核拷贝到`Socket`缓冲区)。



### 为什么需要DMA技术

在DMA以前，I/O的过程是 CPU发出对应的指令给磁盘控制器，然后 磁盘控制器会把数据准备好放入到自己的内存缓存区中，然后产生一个中断。 CPU收到中断后，就会停下手头的工作，把磁盘缓存区中的数据一个一个读入到自己的寄存器中，读完后再写入到内存中。 而这个期间CPU是什么事情都干不了了。



### DMA是什么

**在进行 I/O 设备和内存的数据传输的时候，数据搬运的工作全部交给 DMA 控制器，而 CPU 不再参与任何与数据搬运相关的事情，这样 CPU 就可以去处理别的事务**。



具体过程

1. 用户进程发出I/O请求，将数据读取到自己的用户缓冲区中，进入阻塞状态。
2. 操作系统收到命令后，将I/O发送到DMA中，然后让CPU执行其他任务。
3. DMA将I/O请求发送给磁盘。
4. 磁盘将数据读入到磁盘缓冲区后，告知DMA已经读取完成。
5. DMA收到磁盘的信号后，将数据拷贝到内核缓冲区中。
6. 读取完成后，就告知CPU过来取。
7. CPU就从内核拷贝到用户空间中。

现在基本上每个I/O设备里面都有自己的DMA控制器



### 为什么要对文件传输进行优化（为何要实现零拷贝）

1. 传统的文件传输涉及到了4次用户态与内核态的上下文切换，而上下文切换成本很高。
2. 同时还发生了4次数据拷贝。



所以我们应该提高文件传输的性能，减少 **用户态和内核态**的上下文切换和**内存拷贝**的次数。



### mmap + write

在系统调用read，会把内核缓冲区的数据拷贝到用户缓冲区中。于是为了减少这一步开支，可以用 mmap 替换read。

mmap会直接把内核缓冲区里的数据映射到用户空间中，这样 操作系统内核与用户空间就不需要进行任何的数据拷贝操作了。



而且仍然需要 4 次上下文切换，因为系统调用还是 2 次



### sendfile

可以直接把内核缓冲区的数据拷贝到socket缓冲区中，不再拷贝到用户态中。

主题的流程就是：

1. DMA将磁盘上的数据拷贝到内核缓冲区中。
2. 缓冲区描述符和数据长度传到 socket 缓冲区，这样网卡的 SG-DMA 控制器就可以直接将内核缓存中的数据拷贝到网卡的缓冲区里。

整个过程只涉及到2次数据拷贝。



### 什么是零拷贝，优点是什么？

因为我们没有在内存层面去拷贝数据，也就是说全程没有通过 CPU 来搬运数据，所有的数据都是通过 DMA 来进行传输的。



零拷贝技术的文件传输方式相比传统文件传输的方式，减少了 2 次上下文切换和数据拷贝次数，**只需要 2 次上下文切换和数据拷贝次数，就可以完成文件的传输，而且 2 次的数据拷贝过程，都不需要通过 CPU，2 次都是由 DMA 来搬运。**



### 使用了零拷贝的项目

1. kafka用到了 sendfile() 函数，提升了 I/O 的吞吐率。这也是 Kafka 在处理海量数据为什么这么快的原因之一。
2. Nginx也支持零拷贝技术。



### PageCache

PageCache 实际上就是 从磁盘拷贝到内存缓冲区，这个内存缓冲区就是 PageCache。

在实际应用中，发现 内存不能够完全把磁盘中的数据拷贝到内存中。那么，选择把哪些磁盘数据拷贝到内存中很重要？

所以用 **PageCache 来缓存最近被访问的数据**，当空间不足时淘汰最久未被访问的缓存。所以，读磁盘数据的时候，优先在 PageCache 找，如果数据存在则可以直接返回；如果没有，则从磁盘中读取，然后缓存 PageCache 中。



PageCache还有一个 **预读功能** ， 也就是 除了读取实际需要的数据，还会把后面的数据也一起读取进pagecache中

所以，PageCache 的优点主要是两个：

- 缓存最近被访问的数据；
- 预读功能；





### 为什么大文件（GB级别的文件） PageCache不会起作用？

1. 文件太多，很快就会把PageCache给填满。
2. 而且，由于文件太大了，部分文件数据被再次访问的概率会很低。



所以针对大文件传输，不应该用pageCache，也就是零拷贝。

因为可能由于 PageCache 被大文件占据，而导致「热点」小文件无法利用到 PageCache，这样在高并发的环境下，会带来严重的性能问题。



### 大文件如何传输，用什么实现

**在高并发的场景下，针对大文件的传输的方式，应该使用「异步 I/O + 直接 I/O」来替代零拷贝技术**。也就是绕开PageCache直接读取文件。



使用PageCache的是缓存I/O



### 直接I/O的两个场景

- 应用程序已经实现了磁盘数据的缓存，那么可以不需要 PageCache 再次缓存，减少额外的性能损耗。在 MySQL 数据库中，可以通过参数设置开启直接 I/O，默认是不开启；
- 传输大文件的时候，由于大文件难以命中 PageCache 缓存，而且会占满 PageCache 导致「热点」文件无法充分利用缓存，从而增大了性能开销，因此，这时应该使用直接 I/O。





## I/O多路复用



### 为什么不用进程管理

上下文切换消耗的资源太大



### 为什么不用线程管理

如果每来一个连接就创建一个线程，线程运行完后，还得操作系统还得销毁线程，虽说线程切换的上写文开销不大，但是如果频繁创建和销毁线程，系统开销也是不小的。



### 多线程模型

既然进程间上下文切换的“包袱”很重，那我们就搞个比较轻量级的模型来应对多用户的请求 —— **多线程模型**。单进程中可以运行多个线程，同进程里的线程可以共享进程的部分资源

线程的销毁也会涉及到资源的消耗，可以使用**线程池**的方式来避免线程的频繁创建和销毁，所谓的线程池，就是提前创建若干个线程，这样当由新连接建立时，将这个已连接的 Socket 放入到一个队列里，然后线程池里的线程负责从队列中取出「已连接 Socket 」进行处理。



### I/O多路复用

用一个进程来维护多个Socket，就是I/O多路复用。 使用的方式就是，一个进程虽然任一时刻只能处理一个进程，但我处理每个进程控制在1毫秒以内。 1秒钟就能处理上千个请求。 这种思想就类似于 cpu并发多个进程，时分多路复用。

select/poll/epoll 是如何获取网络事件的呢？在获取事件时，先把所有连接（文件描述符）传给内核，再由内核返回产生了事件的连接，然后在用户态中再处理这些连接对应的请求即可。

select/poll/epoll是三个多路复用的接口，各有各的优势：



#### select/poll

这两个类似，都是将已连接的socket放到一个文件描述符集合中，然后调用select函数将文件描述符集合拷贝到内核中，让内核来检测是否有网络事件的发生，检查的方法就是通过遍历来完成。 当有事情发生的时候，就会将socket标记为可读或可写，放回到用户态中，进行处理。



#### Epoll

实际epoll解决了两个问题：

1. epoll的内核中使用了红黑树来根据进程所有待检测的文件描述字。将需要检测的socket放入到红黑树中，因为红黑树的增删改查复杂度是logn，可以大幅减少了内核和用户空间大量的数据拷贝和内存分配。
2. epoll使用了事件驱动的机制，内核里边维护了一个链表来记录就绪事件。当有事件发生的时候，内核就会将这个socket放入到就绪队列中，当用户调用epoll_wait（）函数的时候，就可以进行处理，而不需要像select和poll进行轮询。



## Reactor和Proactor

### Reactor

像select/poll/epoll，都是直接交给内核态进行检测。

**Reactor也被称为是dispatcher**，也可以理解为，**I/O 多路复用监听事件，收到事件后，根据事件类型分配（Dispatch）给某个进程 / 线程**。



Reactor 模式主要由 Reactor 和处理资源池这两个核心部分组成，它俩负责的事情如下：

- Reactor 负责监听和分发事件，事件类型包含连接事件、读写事件；
- 处理资源池负责处理事件，如 read -> 业务逻辑 -> send；



一般使用的都是`多Reactor多线程的方案`。具体的流程就是：

1. 主线程中的主Reactor对象通过select监控连接建立事件，收到事件后通过Acceptor对象中的accept获取连接，将新的连接分配给某个子线程。
2. 子线程中的SubReactor会将主Reactor分配的对象加入select继续进行监听，并加入了一个handler对其进行处理。
3. 如果有新的事件发生时，SubReactor 对象会调用当前连接对应的 Handler 对象来进行响应。
4. Handler 对象通过 read -> 业务处理 -> send 的流程来完成完整的业务流程。

优点：

1.  主线程和子线程分工明确，主线程只负责接收新连接，子线程负责完成后续的业务处理。
2. 主线程和子线程的交互很简单，主线程只需要把新连接传给子线程，子线程无须返回数据，直接就可以在子线程将处理结果发送给客户端



### Proactor

Proactor是异步网络，即使用了异步I/O技术的网络。





### Reactor和Proactor的区别

1. Reactor是非阻塞同步网络，感知的是就绪可读可写的事件。在每次感知到有事件发生（比如可读就绪事件）后，就需要应用进程主动调用 read 方法来完成数据的读取
2. Proactor是异步I/O网络，感知的是已完成读写的事件。在发起异步读写请求时，需要传入数据缓冲区的地址（用来存放结果数据）等信息，这样系统内核才可以自动帮我们把数据的读写工作完成



## 什么是虚拟内存？ Linux使用的是哪种内存惯例方式



### 什么是虚拟内存

可以引申单片机，单片机内存是没办法同时运行两个程序的。  因为单片机使用的是绝对物理地址。可以把进程所使用的地址「隔离」开来，即让操作系统为每个进程分配独立的一套「**虚拟地址**」，人人都有，大家自己玩自己的地址就行，互不干涉。**操作系统会提供一种机制，将不同进程的虚拟地址和不同内存的物理地址映射起来。**



### 内存分段

**不同的段是有不同的属性的，所以就用分段（\*Segmentation\*）的形式把这些段分离出来。** 分段机制下的虚拟地址由两部分组成，**段选择因子**和**段内偏移量**。

- 段选择因子放在寄存器中，保存最重要的是短号
- 段偏移因子加段基地址就可以得到真实地址。



**存在的问题：**

- 第一个就是**内存碎片**的问题。
- 第二个就是**内存交换的效率低**的问题。**如果内存交换的时候，交换的是一个占内存空间很大的程序，这样整个机器都会显得卡顿。**



### 内存分页

分段的好处就是能产生连续的内存空间，但是会出现「外部内存碎片和内存交换的空间太大」的问题。

**分页是把整个虚拟和物理内存空间切成一段段固定尺寸的大小**

虚拟地址与物理地址之间通过**页表**来映射，**页表**是存储在内存里的，**内存管理单元** （*MMU*）就做将虚拟内存地址转换成物理地址的工作。



流程步骤：

- 把虚拟内存地址，切分成页号和偏移量；
- 根据页号，从页表里面，查询对应的物理页号；
- 直接拿物理页号，加上前面的偏移量，就得到了物理内存地址。



单简单的分页存在有缺陷，就是操作系统可以同时运行多个进程，每个页都需要花空间来存储页表项，那么就需要很大的空间来存储这些页表项。



**多级页表**

设立一级页表，一级页表下再设立二级页表。

虽然看着二级页表占用的空间更多了，但是我们往往不会为一个进程分配那么多内存。这是因为局部性原理。**如果某个一级页表的页表项没有被用到，也就不需要创建这个页表项对应的二级页表了，即可以在需要时才创建二级页表**



**TLB**

多级页表虽然解决了空间上的问题，但是虚拟地址到物理地址的转换就多了几道转换的工序，这显然就降低了这俩地址转换的速度，也就是带来了时间上的开销。

我们可以把最常访问的几个页表项存储到访问速度更快的硬件，也就是Cache。它封装了内存管理单元（*Memory Management Unit*）芯片，它用来完成地址转换和 TLB 的访问与交互。



Linux 系统中虚拟空间分布可分为**用户态**和**内核态**两部分，二者可以分开。**Linux内存使用的是页式内存管理**





**虚拟内存的作用**

- 第一，虚拟内存可以使得进程对运行内存超过物理内存大小，因为程序运行符合局部性原理，CPU 访问内存会有很明显的重复访问的倾向性，对于那些没有被经常使用到的内存，我们可以把它换出到物理内存之外，比如硬盘上的 swap 区域。
- 第二，由于每个进程都有自己的页表，所以每个进程的虚拟内存空间就是相互独立的。进程也没有办法访问其他进程的页表，所以这些页表是私有的，这就解决了多进程之间地址冲突的问题。
- 第三，页表里的页表项中除了物理地址之外，还有一些标记属性的比特，比如控制一个页的读写权限，标记该页是否存在等。在内存访问方面，操作系统提供了更好的安全性。



## 什么是malloc，和New的区别是什么

**new** 的功能是在堆区新建一个对象，并返回该对象的指针。

而**malloc** 只是机械的分配一块虚拟内存空间，如果用mallco 在堆区创建一个对象的话，是不会调用构造函数的。



## 内存管理



### 内存分配的全过程

1. 应用程序通过malloc函数申请内存。CPU读了malloc申请的虚拟内存，发现没有，就是产生缺页中断。进程会从用户态切换到内核态，并将缺页中断交给内核的 Page Fault Handler （缺页中断函数）处理。
2. 缺页中断处理函数就会看看有没有空闲的物理内存，有的话就分配，并将物理内存和虚拟内存建立联系，没有的话，内核就进行内存回收。
   - **后台内存回收**（kswapd）：在物理内存紧张的时候，会唤醒 kswapd 内核线程来回收内存，这个回收内存的过程**异步**的，不会阻塞进程的执行。
   - **直接内存回收**（direct reclaim）：如果后台异步回收跟不上进程内存申请的速度，就会开始直接回收，这个回收内存的过程是**同步**的，会阻塞进程的执行。
3. 如果直接内存回收后，空闲的物理内存仍然无法满足此次物理内存的申请，那么内核就会放最后的大招了 ——**触发 OOM （Out of Memory）机制**。
   - OOM Killer 机制会根据算法选择一个占用物理内存较高的进程，然后将其杀死，以便释放内存资源，如果物理内存依然不足，OOM Killer 会继续杀死占用物理内存较高的进程，直到释放足够的内存位置。



### 可以被回收的内存类型

1. **文件页**：内核缓存的磁盘数据（Buffer）和内核缓存的文件数据（Cache）。
2. **匿名页：** 这部分内存没有实际载体，不像文件缓存有硬盘文件这样一个载体，比如堆、栈数据等。因为有可能会再次访问，所以不能直接删除，**回收的方式是通过 Linux 的 Swap 机制**，Swap 会把不常访问的内存先写到磁盘中，然后释放这些内存，给其他更需要的进程使用。



### 如何保护一个进程不被OOM杀掉？

如何确定OOM杀掉哪些进程？

在 Linux 内核里有一个 `oom_badness()` 函数，它会把系统中可以被杀掉的进程扫描一遍，并对每个进程打分，得分最高的进程就会被首先杀掉。

- 进程已经使用的物理内存页面数。
- 每个进程的 OOM 校准值。可以通过配置文件来配置的。



### 如果4GB的内存，应用程序申请8GB的会怎么样

1. 32位系统会报错，因为它指运行一个进程申请3G的内存
2. 64位系统不会报错，因为它最多运行申请128TB的虚拟内存空间。

主要因为它分配的并不是物理内存，而是虚拟内存。



### 如何避免预读失效和缓存污染问题



#### 什么是预读机制？

我们这里可以举Linux和MySQL的缓存

**Linux的缓存机制中，会将文件读取后，放在Page Cache中,而文件的读取不是应用程序想读取多少我们给多少，而是在应用程序要求的基础上，Linux还会额外读取与它邻接的块**

**MySQL的缓存机制中，则是设计了一个Buffer Pool。MySQL Innodb 存储引擎的 Buffer Pool 也有类似的预读机制，MySQL 从磁盘加载页时，会提前把它相邻的页一并加载进来，目的是为了减少磁盘 IO**



#### 什么是预读失效？

如果**这些被提前加载进来的页，并没有被访问**，相当于这个预读工作是白做了，这个就是**预读失效**。



**如何避免：**

最好就是**让预读页停留在内存里的时间要尽可能的短，让真正被访问的页才移动到 LRU 链表的头部，从而保证真正被读取的热数据留在内存里的时间尽可能长**。

对LRU算法进行改造

1. Linux实现了两个LRU链表： 活跃LRU链表，非活跃LRU链表
2. MySQL的Innodb存储引擎是在一个LRU 链表上划分来 2 个区域：**young 区域 和 old 区域**

这两个改进方式，设计思想都是类似的，**都是将数据分为了冷数据和热数据，然后分别进行 LRU 算法**。不再像传统的 LRU 算法那样，所有数据都只用一个 LRU 算法管理。



#### 什么是缓存污染

1. 当我们在批量读取数据的时候，由于数据被访问了一次，这些大量数据都会被加入到「活跃 LRU 链表」里，然后之前缓存在活跃 LRU 链表（或者 young 区域）里的热点数据全部都被淘汰了，**如果这些大量的数据在很长一段时间都不会被访问的话，那么整个活跃 LRU 链表（或者 young 区域）就被污染了**。
2. 当某一个 SQL 语句**扫描了大量的数据**时，在 Buffer Pool 空间比较有限的情况下，可能会将 **Buffer Pool 里的所有页都替换出去，导致大量热数据被淘汰了**，等这些热数据又被再次访问的时候，由于缓存未命中，就会产生大量的磁盘 I/O，MySQL 性能就会急剧下降。



**如何避免：**

提高进入活跃LRU链表的门槛

1. **Linux 操作系统**：在内存页被访问**第二次**的时候，才将页从 inactive list 升级到 active list 里。
2. **MySQL Innodb**：在内存页被访问**第二次**的时候，并不会马上将该页从 old 区域升级到 young 区域，因为还要进行**停留在 old 区域的时间判断**：
   - 如果第二次的访问时间与第一次访问的时间**在 1 秒内**（默认值），那么该页就**不会**被从 old 区域升级到 young 区域；
   - 如果第二次的访问时间与第一次访问的时间**超过 1 秒**，那么该页就**会**从 old 区域升级到 young 区域；



### 进程虚拟内存的管理



## 一致性哈希



### 用来解决什么问题的

当我们想提高系统的容量，就会将数据水平切分到不同的节点来存储，也就是将数据分布到了不同的节点。比如**一个分布式 KV（key-valu） 缓存系统，某个 key 应该到哪个或者哪些节点上获得，应该是确定的**，不是说任意访问一个节点都可以得到缓存结果的。

因此，我们要想一个能应对分布式系统的负载均衡算法。一般会想到使用**哈希算法**。对同一个关键字用哈希计算，然后就可以根据key确定一个节点了，但是有一个很致命的问题，**如果节点数量发生了变化，也就是在对系统做扩容或者缩容时，必须迁移改变了映射关系的数据**，否则会出现查询不到数据的问题。



### 一致性哈希是怎么做的

一致哈希算法也用了取模运算，但与哈希算法不同的是，哈希算法是对节点的数量进行取模运算，而**一致哈希算法是对 2^32 进行取模运算，是一个固定的值 **。可以想象成是一个哈希环

一致性哈希要进行两步哈希：

- 第一步：对存储节点进行哈希计算，也就是对存储节点做哈希映射，比如根据节点的 IP 地址进行哈希；
- 第二步：当对数据进行存储或访问时，对数据进行哈希映射；

所以，**一致性哈希是指将「存储节点」和「数据」都映射到一个首尾相连的哈希环上**。



#### 缺点

**一致性哈希算法并不保证节点能够在哈希环上分布均匀**，这样就会带来一个问题，会有大量的请求集中在一个节点上。



#### 解决办法

可以加入虚拟节点，不将真实节点映射到哈希环上，而是将虚拟节点映射到哈希环上。
